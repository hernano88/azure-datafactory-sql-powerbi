# ETL en Azure: Data Factory + SQL Database

Proyecto de pipeline en **Azure Data Factory** para ingerir datos de COVID desde Data Lake y 
persistirlos en **Azure SQL Database**.  

---

## ğŸ¯ Objetivo
Implementar un pipeline en Azure que:
- Ingesta datos desde archivos CSV.
- Valida la presencia de los archivos en Data Lake.
- Copia y persiste los datos en una tabla de Azure SQL Database (`covid_population`).

---

## ğŸš€ Pipeline en Data Factory
Pipeline orquestado que incluye:
- ValidaciÃ³n de archivos.
- ObtenciÃ³n de metadatos.
- Actividad **Copy Data** para cargar informaciÃ³n en SQL.

ğŸ“¸ Ejemplo de actividad *Copy Data* en el pipeline:
![Copy Data Pipeline](pictures/copy_data_pipeline.PNG)

---

## ğŸ›¢ï¸ Persistencia en SQL Database
Los datos se almacenan en una tabla relacional dentro de **Azure SQL Database**, accesible vÃ­a editor de consultas.  

ğŸ“¸ Vista de la tabla con los datos cargados:
![SQL Database](pictures/sql_database.PNG)

---

## ğŸ“Š Resultados esperados
- Carga exitosa de datos en SQL Database.
- PreparaciÃ³n para su futura visualizaciÃ³n en Power BI.

---

## ğŸ”§ TecnologÃ­as utilizadas
- **Azure Data Factory**
- **Azure Data Lake Storage**
- **Azure SQL Database**


